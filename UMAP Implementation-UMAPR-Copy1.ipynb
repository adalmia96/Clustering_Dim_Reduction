{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mnist in /home/adalmia1/anaconda3/lib/python3.7/site-packages (0.2.2)\r\n",
      "Requirement already satisfied: numpy in /home/adalmia1/anaconda3/lib/python3.7/site-packages (from mnist) (1.19.5)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adalmia1/anaconda3/lib/python3.7/site-packages/umap/__init__.py:9: UserWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\"Tensorflow not installed; ParametricUMAP will be unavailable\")\n"
     ]
    }
   ],
   "source": [
    "!pip3 install mnist\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numba\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups, fetch_openml\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, KernelPCA\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import mnist\n",
    "from sklearn import datasets,metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pynndescent import NNDescent\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full MNIST dataset\n",
    "MNIST_X_train = mnist.train_images()\n",
    "MNIST_n_samples = len(MNIST_X_train)\n",
    "MNIST_X_train = MNIST_X_train.reshape((len(MNIST_X_train), -1)) \n",
    "MNIST_y_train = mnist.train_labels()\n",
    "\n",
    "\n",
    "# Load digits dataset\n",
    "digits = datasets.load_digits()\n",
    "digits_n_samples = len(digits.images)\n",
    "digits_X_train = digits.images.reshape((digits_n_samples, -1))\n",
    "digits_y_train = digits.target\n",
    "\n",
    "\n",
    "#Load 20 NewsGroup\n",
    "vectorizer = TfidfVectorizer(min_df=5, stop_words='english') \n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='all')\n",
    "newsgroups_X_train = vectorizer.fit_transform(newsgroups_train.data).toarray()\n",
    "newsgroups_n_train = len(newsgroups_X_train)\n",
    "newsgroups_y_train = newsgroups_train.target\n",
    "\n",
    "\n",
    "\n",
    "fmnist = fetch_openml('Fashion-MNIST', version=1)\n",
    "#print(fmnist)\n",
    "f_mnist_X = fmnist.data\n",
    "f_mnist_n = len(f_mnist_X)\n",
    "fmnist_y = fmnist.target.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "n = f_mnist_n\n",
    "X_train = f_mnist_X\n",
    "y_train = fmnist_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a,b hyperparams given the MIN_DIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters a = 1.5768410960900492 and b = 0.8949051206485682\n"
     ]
    }
   ],
   "source": [
    "def find_ab(MIN_DIST=0.1):\n",
    "    x = np.linspace(0, 3, 1000)\n",
    "  \n",
    "    def f(x, min_dist):\n",
    "        y = []\n",
    "        for i in range(len(x)):\n",
    "            if(x[i] <= min_dist):\n",
    "                y.append(1)\n",
    "            else:\n",
    "                y.append(np.exp(- x[i] + min_dist))\n",
    "        return y\n",
    "\n",
    "    dist_low_dim = lambda x, a, b: 1 / (1 + a*x**(2*b))\n",
    "\n",
    "    p , _ = optimize.curve_fit(dist_low_dim, x, f(x, MIN_DIST))\n",
    "\n",
    "    a = p[0]\n",
    "    b = p[1] \n",
    "    print(\"Hyperparameters a = \" + str(a) + \" and b = \" + str(b))\n",
    "    return a, b\n",
    "a, b = find_ab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the approximate nearest neighbor and new distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Nearest Neighbors\n",
      "UMAP(dens_frac=0.0, dens_lambda=0.0, n_components=700, n_epochs=800,\n",
      "     verbose=True)\n",
      "Construct fuzzy simplicial set\n",
      "Mon Feb  8 21:42:56 2021 Finding Nearest Neighbors\n",
      "Mon Feb  8 21:42:56 2021 Building RP forest with 18 trees\n",
      "Mon Feb  8 21:42:59 2021 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\t 4  /  16\n",
      "\tStopping threshold met -- exiting after 4 iterations\n",
      "Mon Feb  8 21:43:20 2021 Finished Nearest Neighbor Search\n",
      "Mon Feb  8 21:43:24 2021 Construct embedding\n",
      "\tcompleted  0  /  800 epochs\n",
      "\tcompleted  80  /  800 epochs\n",
      "\tcompleted  160  /  800 epochs\n",
      "\tcompleted  240  /  800 epochs\n",
      "\tcompleted  320  /  800 epochs\n",
      "\tcompleted  400  /  800 epochs\n",
      "\tcompleted  480  /  800 epochs\n",
      "\tcompleted  560  /  800 epochs\n",
      "\tcompleted  640  /  800 epochs\n",
      "\tcompleted  720  /  800 epochs\n",
      "Mon Feb  8 22:25:50 2021 Finished embedding\n",
      "Mon Feb  8 22:25:51 2021 Building RP forest with 18 trees\n",
      "Mon Feb  8 22:25:53 2021 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\tStopping threshold met -- exiting after 2 iterations\n",
      "Finished Nearest Neighbor Search\n"
     ]
    }
   ],
   "source": [
    "def get_dists(indices, X):\n",
    "  ind = []\n",
    "  dist = []\n",
    "  for i, xi in enumerate(X):\n",
    "    group_embeds = X[indices[i]]\n",
    "    dist = np.sum((group_embeds - X[i])**2,axis=1)\n",
    "    dist = np.sqrt(dist)\n",
    "    dist_ind = np.argsort(dist)[:n_neighbors]\n",
    "    dist.append(dist[dist_ind])\n",
    "    ind.append(indices[i][dist_ind])\n",
    "  return ind, dist\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nearest_neighbors(X, n_neighbors=15):\n",
    "    \"\"\"Compute the ``n_neighbors`` nearest points for each data point in ``X``\n",
    "    under ``metric``. This may be exact, but more likely is approximated via\n",
    "    nearest neighbor descent. \"\"\"\n",
    "    print(\"Finding Nearest Neighbors\")\n",
    "    \n",
    "    model = UMAP(n_neighbors = 15, min_dist = 0.1 , n_components = 700, n_epochs = 800, verbose = True)\n",
    "    Xr = model.fit_transform(X)\n",
    "    \n",
    "    n_trees = min(64, 5 + int(round((X.shape[0]) ** 0.5 / 20.0)))\n",
    "    n_iters = max(5, int(round(np.log2(X.shape[0]))))\n",
    "\n",
    "    knn_search_index = NNDescent(Xr, n_neighbors=n_neighbors, metric='euclidean', metric_kwds={}, random_state=None, n_trees=n_trees, n_iters=n_iters, max_candidates=60,low_memory=True, n_jobs= 4,verbose=True)\n",
    "    \n",
    "    knn_indices = knn_search_index._neighbor_graph[0].copy()\n",
    "    knn_dists = knn_search_index._neighbor_graph[1].copy()\n",
    "    \n",
    "    #knn_dists = np.array(knn_dists)\n",
    "    #knn_indices = np.array(knn_indices)\n",
    "    \n",
    "    \n",
    "    print(\"Finished Nearest Neighbor Search\")\n",
    "    return knn_indices, knn_dists, knn_search_index\n",
    "\n",
    "  \n",
    "knn_indices, knn_dists, knn_search_index = nearest_neighbors(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Fuzzy Simplicial Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rho and sigma\n",
      "\tcompleted  0  /  70000 epochs\n",
      "\tcompleted  7000  /  70000 epochs\n",
      "\tcompleted  14000  /  70000 epochs\n",
      "\tcompleted  21000  /  70000 epochs\n",
      "\tcompleted  28000  /  70000 epochs\n",
      "\tcompleted  35000  /  70000 epochs\n",
      "\tcompleted  42000  /  70000 epochs\n",
      "\tcompleted  49000  /  70000 epochs\n",
      "\tcompleted  56000  /  70000 epochs\n",
      "\tcompleted  63000  /  70000 epochs\n"
     ]
    }
   ],
   "source": [
    "def smooth_knn_dist(distances, n_neighbors=15, n_iter=64):\n",
    "    \"\"\"Compute a continuous version of the distance to the kth nearest\n",
    "    neighbor. That is, this is similar to knn-distance but allows continuous\n",
    "    k values rather than requiring an integral k. In essence we are simply\n",
    "    computing the distance such that the cardinality of fuzzy set we generate\n",
    "    is k.\n",
    "    \"\"\"\n",
    "    \n",
    "    target = np.log2(n_neighbors)\n",
    "    rho = np.zeros(distances.shape[0], dtype=np.float32)\n",
    "    sigma = np.zeros(distances.shape[0], dtype=np.float32)\n",
    "    \n",
    "    print(\"Calculating rho and sigma\")\n",
    "    for i in range(distances.shape[0]):\n",
    "        rho[i] = distances[i][1]\n",
    "        \n",
    "        lo = 0.0\n",
    "        hi = np.inf\n",
    "        mid = 1.0\n",
    "        \n",
    "        for n in range(n_iter):\n",
    "            \n",
    "            #Calculate probability\n",
    "            psum = 0.0\n",
    "            for j in range(1, distances.shape[1]):\n",
    "                d = distances[i, j] - rho[i]\n",
    "                psum += np.exp(-(d / mid)) if d > 0 else 1.0 \n",
    "                \n",
    "            #binary search to find sigma\n",
    "            if np.fabs(psum - target) < 1e-5: #SMOOTH_K_TOLERANCE\n",
    "                break\n",
    "            if psum > target:\n",
    "                hi = mid\n",
    "                mid = (lo + hi) / 2.0\n",
    "            else:\n",
    "                lo = mid\n",
    "                if hi == np.inf:\n",
    "                    mid *= 2\n",
    "                else:\n",
    "                    mid = (lo + hi) / 2.0\n",
    "        \n",
    "        if i % int(distances.shape[0] / 10) == 0:\n",
    "            print(\"\\tcompleted \", i, \" / \", distances.shape[0], \"epochs\")\n",
    "            \n",
    "        sigma[i] = mid\n",
    "\n",
    "    return sigma, rho\n",
    "\n",
    "\n",
    "def compute_membership_strengths(knn_indices, knn_dists, sigmas, rhos, bipartite=False):\n",
    "    \"\"\"Construct the membership strength data for the 1-skeleton of each local\n",
    "    fuzzy simplicial set -- this is formed as a sparse matrix where each row is\n",
    "    a local fuzzy simplicial set, with a membership strength for the\n",
    "    1-simplex to each other data point.\n",
    "    \"\"\"\n",
    "    n_samples = knn_indices.shape[0]\n",
    "    n_neighbors = knn_indices.shape[1]\n",
    "\n",
    "    rows = np.zeros(knn_indices.size, dtype=np.int32)\n",
    "    cols = np.zeros(knn_indices.size, dtype=np.int32)\n",
    "    vals = np.zeros(knn_indices.size, dtype=np.float32)\n",
    "    dists = np.zeros(knn_indices.size, dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_neighbors):\n",
    "            if (bipartite == False) & (knn_indices[i, j] == i):\n",
    "                val = 0.0\n",
    "            elif knn_dists[i, j] - rhos[i] <= 0.0 or sigmas[i] == 0.0:\n",
    "                val = 1.0\n",
    "            else:\n",
    "                val = np.exp(-((knn_dists[i, j] - rhos[i]) / (sigmas[i])))\n",
    "            rows[i * n_neighbors + j] = i\n",
    "            cols[i * n_neighbors + j] = knn_indices[i, j]\n",
    "            vals[i * n_neighbors + j] = val\n",
    "            dists[i * n_neighbors + j] = knn_dists[i, j]\n",
    "\n",
    "    return rows, cols, vals, dists\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "def fuzzy_simplicial_set(X, knn_indices, knn_dists, n_neighbors=15):\n",
    "    \"\"\"Given a set of data X, a neighborhood size, and a measure of distance\n",
    "    compute the fuzzy simplicial set (here represented as a fuzzy graph in\n",
    "    the form of a sparse matrix) associated to the data. This is done by\n",
    "    locally approximating geodesic distance at each point, creating a fuzzy\n",
    "    simplicial set for each such point, and then combining all the local\n",
    "    fuzzy simplicial sets into a global one via a fuzzy union.\n",
    "    \"\"\"\n",
    "    \n",
    "    knn_dists = knn_dists.astype(np.float32)\n",
    "    sigmas, rhos = smooth_knn_dist(knn_dists)\n",
    "    \n",
    "    \n",
    "    rows, cols, vals, dists = compute_membership_strengths(knn_indices, knn_dists, sigmas, rhos)\n",
    "\n",
    "    #Calculate the fuzzy_simplicial_set\n",
    "    Pij = scipy.sparse.coo_matrix((vals, (rows, cols)), shape=(X.shape[0], X.shape[0]))\n",
    "    Pij.eliminate_zeros()\n",
    "    \n",
    "    Pji = Pij.transpose()\n",
    "    prod_matrix = Pij.multiply(Pji) \n",
    "    P = (Pij + Pji - prod_matrix)\n",
    "    P.eliminate_zeros()\n",
    "    \n",
    "    #Calculate the fuzzy simplex distance matrix\n",
    "    dmat = scipy.sparse.coo_matrix((dists, (rows, cols)), shape=(X.shape[0], X.shape[0]))\n",
    "    dists = dmat.maximum(dmat.transpose()).todok()\n",
    "\n",
    "    return P, sigmas, rhos, dists\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P, sigmas, rhos, dists = fuzzy_simplicial_set(X_train, knn_indices, knn_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_layout(data, graph, dim):\n",
    "    \"\"\"Given a graph compute the spectral embedding of the graph. This is\n",
    "    simply the eigenvectors of the laplacian of the graph. Here we use the\n",
    "    normalized laplacian.\n",
    "    \"\"\"\n",
    "    diag_data = np.asarray(graph.sum(axis=0))\n",
    "    # Normalized Laplacian\n",
    "    I = scipy.sparse.identity(graph.shape[0], dtype=np.float64)\n",
    "    D = scipy.sparse.spdiags(1.0 / np.sqrt(diag_data), 0, graph.shape[0], graph.shape[0])\n",
    "    L = I - D * graph * D\n",
    "    k = dim + 1\n",
    "    eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(L, k, which=\"SM\")\n",
    "    order = np.argsort(eigenvalues)[1:k]\n",
    "    return eigenvectors[:, order]\n",
    "  \n",
    "def random_layout(data, graph, dim):\n",
    "    random_state = np.random.RandomState(1234)\n",
    "    return random_state.uniform(low=-10.0, high=10.0, size=(graph.shape[0], dim))\n",
    "  \n",
    "  \n",
    "def init_embeddings(X, P, n_components):\n",
    "  \n",
    "   #Spectral init\n",
    "  initialisation = spectral_layout(X, P, n_components)\n",
    "  \n",
    "  #Add noise\n",
    "  expansion = 10.0 / np.abs(initialisation).max()\n",
    "  random_state = check_random_state(0)\n",
    "  embedding = (initialisation * expansion).astype(np.float32) + random_state.normal(scale=0.0001, size=[P.shape[0], n_components]).astype(np.float32)\n",
    "  \n",
    "  embedding = (10.0 * (embedding - np.min(embedding, 0)) / (np.max(embedding, 0) - np.min(embedding, 0))).astype(np.float32, order=\"C\")\n",
    "  return embedding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adalmia1/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1226938,)\n",
      "\tcompleted  0  /  800 epochs\n",
      "\tcompleted  80  /  800 epochs\n",
      "\tcompleted  160  /  800 epochs\n",
      "\tcompleted  240  /  800 epochs\n",
      "\tcompleted  320  /  800 epochs\n",
      "\tcompleted  400  /  800 epochs\n",
      "\tcompleted  480  /  800 epochs\n",
      "\tcompleted  560  /  800 epochs\n",
      "\tcompleted  640  /  800 epochs\n",
      "\tcompleted  720  /  800 epochs\n"
     ]
    }
   ],
   "source": [
    "INT32_MIN = np.iinfo(np.int32).min + 1\n",
    "INT32_MAX = np.iinfo(np.int32).max - 1\n",
    "\n",
    "\n",
    "def make_epochs_per_sample(weights, n_epochs):\n",
    "    \"\"\"Given a set of weights and number of epochs generate the number of\n",
    "    epochs per sample for each weight.\n",
    "    Returns\n",
    "    -------\n",
    "    An array of number of epochs per sample, one for each 1-simplex.\n",
    "    \"\"\"\n",
    "    result = -1.0 * np.ones(weights.shape[0], dtype=np.float64)\n",
    "    n_samples = n_epochs * (weights / weights.max())\n",
    "    \n",
    "    result[n_samples > 0] = float(n_epochs) / n_samples[n_samples > 0]\n",
    "    print(result.shape)\n",
    "    return result\n",
    "\n",
    "  \n",
    "@numba.njit()\n",
    "def clip(val):\n",
    "    \"\"\"Standard clamping of a value into a fixed range (in this case -4.0 to\n",
    "    4.0)\n",
    "    \"\"\"\n",
    "    if val > 4.0:\n",
    "        return 4.0\n",
    "    elif val < -4.0:\n",
    "        return -4.0\n",
    "    else:\n",
    "        return val  \n",
    "  \n",
    "\n",
    "  \n",
    "@numba.njit(\n",
    "    \"f4(f4[::1],f4[::1])\",\n",
    "    fastmath=True,\n",
    "    cache=True,\n",
    "    locals={\n",
    "        \"result\": numba.types.float32,\n",
    "        \"diff\": numba.types.float32,\n",
    "        \"dim\": numba.types.int32,\n",
    "    },\n",
    ")\n",
    "def rdist(x, y):\n",
    "    result = 0.0\n",
    "    dim = x.shape[0]\n",
    "    for i in range(dim):\n",
    "        diff = x[i] - y[i]\n",
    "        result += diff * diff\n",
    "\n",
    "    return result\n",
    "  \n",
    "  \n",
    "  \n",
    "@numba.njit(\"i4(i8[:])\")\n",
    "def tau_rand_int(state):\n",
    "    \"\"\"A fast (pseudo)-random number generator.\n",
    "    A (pseudo)-random int32 value\n",
    "    \"\"\"\n",
    "    state[0] = (((state[0] & 4294967294) << 12) & 0xFFFFFFFF) ^ (\n",
    "        (((state[0] << 13) & 0xFFFFFFFF) ^ state[0]) >> 19\n",
    "    )\n",
    "    state[1] = (((state[1] & 4294967288) << 4) & 0xFFFFFFFF) ^ (\n",
    "        (((state[1] << 2) & 0xFFFFFFFF) ^ state[1]) >> 25\n",
    "    )\n",
    "    state[2] = (((state[2] & 4294967280) << 17) & 0xFFFFFFFF) ^ (\n",
    "        (((state[2] << 3) & 0xFFFFFFFF) ^ state[2]) >> 11\n",
    "    )\n",
    "\n",
    "    return state[0] ^ state[1] ^ state[2]\n",
    "\n",
    "  \n",
    "def optimize_layout_euclidean_single_epoch(head_embedding, tail_embedding, head,tail,n_vertices,epochs_per_sample,a,b,rng_state,dim,move_other,alpha,epochs_per_negative_sample,epoch_of_next_negative_sample,epoch_of_next_sample,n):\n",
    "    for i in numba.prange(epochs_per_sample.shape[0]):\n",
    "        if epoch_of_next_sample[i] <= n:\n",
    "            j = head[i]\n",
    "            k = tail[i]\n",
    "\n",
    "            current = head_embedding[j]\n",
    "            other = tail_embedding[k]\n",
    "\n",
    "            \n",
    "            dist_squared = rdist(current, other)\n",
    "            \n",
    "            grad_coeff = -2.0 * a * b * pow(dist_squared, b - 1.0) \n",
    "            grad_coeff /= (a*pow(dist_squared, b) + 1.0)\n",
    "\n",
    "            for d in range(dim): \n",
    "                grad_d = clip(grad_coeff * (current[d] - other[d]))\n",
    "                current[d] += grad_d * alpha\n",
    "                if move_other:\n",
    "                    other[d] += -grad_d * alpha\n",
    "\n",
    "            epoch_of_next_sample[i] += epochs_per_sample[i]\n",
    "\n",
    "            n_neg_samples = int((n - epoch_of_next_negative_sample[i]) / epochs_per_negative_sample[i])\n",
    "\n",
    "            for p in range(n_neg_samples):\n",
    "              \n",
    "                k = tau_rand_int(rng_state) % n_vertices\n",
    "                other = tail_embedding[k]\n",
    "                dist_squared = rdist(current, other)\n",
    "\n",
    "                if dist_squared > 0.0:\n",
    "                    grad_coeff = 2.0  * b \n",
    "                    grad_coeff /= (0.001 + dist_squared) * (a * pow(dist_squared, b) + 1)\n",
    "                elif j == k:\n",
    "                    continue\n",
    "                else:\n",
    "                    grad_coeff = 0.0\n",
    "\n",
    "                for d in range(dim):\n",
    "                    if grad_coeff > 0.0:\n",
    "                        grad_d = clip(grad_coeff * (current[d] - other[d]))\n",
    "                    else:\n",
    "                        grad_d = 4.0\n",
    "                    current[d] += grad_d * alpha\n",
    "\n",
    "            epoch_of_next_negative_sample[i] += (n_neg_samples * epochs_per_negative_sample[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "def simplicial_set_embedding(X, P, n_components, initial_alpha, a, b, gamma, negative_sample_rate):\n",
    "    \"\"\"Perform a fuzzy simplicial set embedding, using a specified\n",
    "    initialisation method and then minimizing the fuzzy set cross entropy\n",
    "    between the 1-skeletons of the high and low dimensional fuzzy simplicial\n",
    "    sets.\n",
    "    \"\"\"\n",
    "    graph = P.tocoo()\n",
    "    graph.sum_duplicates()\n",
    "    n_vertices = graph.shape[1]\n",
    "\n",
    "    n_epochs = 800\n",
    "    \n",
    "    embedding = init_embeddings(X_train, P, n_components)\n",
    "    \n",
    "    #Make epochs\n",
    "    epochs_per_sample = make_epochs_per_sample(graph.data, n_epochs)\n",
    "   \n",
    "    \n",
    "    head = graph.row\n",
    "    tail = graph.col\n",
    "    weight = graph.data\n",
    "    \n",
    "    random_state = check_random_state(0)\n",
    "    rng_state = random_state.randint(INT32_MIN, INT32_MAX, 3).astype(np.int64)\n",
    "\n",
    "    \n",
    "    #Optimize Step\n",
    "    head_embedding = embedding\n",
    "    tail_embedding = embedding\n",
    "    \n",
    "    \n",
    "    move_other = head_embedding.shape[0] == tail_embedding.shape[0]\n",
    "    \n",
    "    \n",
    "    epochs_per_negative_sample = epochs_per_sample / negative_sample_rate\n",
    "    epoch_of_next_negative_sample = epochs_per_negative_sample.copy()\n",
    "    \n",
    "    #print(epoch_of_next_negative_sample)\n",
    "    \n",
    "    epoch_of_next_sample = epochs_per_sample.copy()\n",
    "    #print(epoch_of_next_sample)\n",
    "\n",
    "    \n",
    "    optimize_fn = numba.njit(optimize_layout_euclidean_single_epoch, fastmath=True, parallel=False)\n",
    "    \n",
    "    alpha = initial_alpha\n",
    "    \n",
    "\n",
    "    for n in range(n_epochs):\n",
    "\n",
    "\n",
    "        optimize_fn(\n",
    "            head_embedding,\n",
    "            tail_embedding,\n",
    "            head,\n",
    "            tail,\n",
    "            n_vertices,\n",
    "            epochs_per_sample,\n",
    "            a,\n",
    "            b,\n",
    "            rng_state,\n",
    "            n_components,\n",
    "            move_other,\n",
    "            alpha,\n",
    "            epochs_per_negative_sample,\n",
    "            epoch_of_next_negative_sample,\n",
    "            epoch_of_next_sample,\n",
    "            n\n",
    "        )\n",
    "\n",
    "        alpha = initial_alpha * (1.0 - (float(n) / float(n_epochs)))\n",
    "\n",
    "        if n % int(n_epochs / 10) == 0:\n",
    "            print(\"\\tcompleted \", n, \" / \", n_epochs, \"epochs\")\n",
    "\n",
    "    return head_embedding\n",
    "\n",
    "\n",
    "  \n",
    "embeds = simplicial_set_embedding(X_train, P, 500, 1, a, b, 1, 5)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = []\n",
    "colors += cm.get_cmap(\"Set3\").colors\n",
    "colors += cm.get_cmap(\"Set2\").colors\n",
    "my_cmap = ListedColormap(colors)\n",
    "\n",
    "plt.scatter(embeds[:, 0], embeds[:, 1], c = y_train.astype(int), cmap = my_cmap, s = 50)\n",
    "plt.title('UMAP', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=20, random_state=2)\n",
    "y_pred_train = kmeans.fit_predict(embeds)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary Score: 0.724\n",
      "Adjusted Mutual Information Score: 0.613\n",
      "Adjusted Rand Index Score: 0.412\n",
      "Normalized Mutual Information Score: 0.613\n",
      "Homogeneity: 0.700\n",
      "Completeness: 0.546\n",
      "V-measure: 0.613\n"
     ]
    }
   ],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
    "def evaluate(y, y_pred): \n",
    "  print(\"Accurary Score: %0.3f\" % purity_score(y, y_pred))\n",
    "  print(\"Adjusted Mutual Information Score: %0.3f\" % metrics.adjusted_mutual_info_score(y, y_pred))\n",
    "  print(\"Adjusted Rand Index Score: %0.3f\" % metrics.adjusted_rand_score(y, y_pred))\n",
    "  print(\"Normalized Mutual Information Score: %0.3f\" % metrics.normalized_mutual_info_score(y, y_pred))\n",
    "\n",
    "  print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(y, y_pred))\n",
    "  print(\"Completeness: %0.3f\" % metrics.completeness_score(y, y_pred))\n",
    "  print(\"V-measure: %0.3f\" % metrics.v_measure_score(y, y_pred))\n",
    "\n",
    "\n",
    "evaluate(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(dens_frac=0.0, dens_lambda=0.0, n_components=500, verbose=True)\n",
      "Construct fuzzy simplicial set\n",
      "Tue Feb  9 07:43:57 2021 Finding Nearest Neighbors\n",
      "Tue Feb  9 07:43:57 2021 Building RP forest with 18 trees\n",
      "Tue Feb  9 07:43:58 2021 NN descent for 16 iterations\n",
      "\t 1  /  16\n",
      "\t 2  /  16\n",
      "\t 3  /  16\n",
      "\t 4  /  16\n",
      "\tStopping threshold met -- exiting after 4 iterations\n",
      "Tue Feb  9 07:44:02 2021 Finished Nearest Neighbor Search\n",
      "Tue Feb  9 07:44:03 2021 Construct embedding\n",
      "\tcompleted  0  /  200 epochs\n",
      "\tcompleted  20  /  200 epochs\n",
      "\tcompleted  40  /  200 epochs\n",
      "\tcompleted  60  /  200 epochs\n",
      "\tcompleted  80  /  200 epochs\n",
      "\tcompleted  100  /  200 epochs\n",
      "\tcompleted  120  /  200 epochs\n",
      "\tcompleted  140  /  200 epochs\n",
      "\tcompleted  160  /  200 epochs\n",
      "\tcompleted  180  /  200 epochs\n",
      "Tue Feb  9 07:59:28 2021 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "\n",
    "\n",
    "model = UMAP(n_neighbors = 15, min_dist = 0.1, n_components = 500, verbose = True)\n",
    "embeds = model.fit_transform(X_train)\n",
    "#plt.scatter(umap[:, 0], umap[:, 1], c = y_train.astype(int), cmap = my_cmap, s = 50)\n",
    "#plt.title('UMAP', fontsize = 20)\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary Score: 0.721\n",
      "Adjusted Mutual Information Score: 0.609\n",
      "Adjusted Rand Index Score: 0.399\n",
      "Normalized Mutual Information Score: 0.609\n",
      "Homogeneity: 0.695\n",
      "Completeness: 0.542\n",
      "V-measure: 0.609\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=20, random_state=2)\n",
    "y_pred_train = kmeans.fit_predict(embeds)\n",
    "\n",
    "evaluate(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
